{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install labml-nn --quiet"
      ],
      "metadata": {
        "id": "17YMt-PuwqJ3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from labml_nn.utils import clone_module_list\n",
        "from feed_forward import FeedForward\n",
        "from mha import MultiHeadAttention\n",
        "from positional_encoding import get_positional_encoding"
      ],
      "metadata": {
        "id": "pqdtZBHgvvqJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsWithPositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model: int, n_vocab: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Embedding(n_vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.register_buffer('positional_encodings', get_positional_encoding(d_model, max_len))\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "        pe = self.positional_encodings[:x.shape[0]].requires_grad_(False)\n",
        "        return self.linear(x) * math.sqrt(self.d_model) + pe"
      ],
      "metadata": {
        "id": "sgIlQJciwi0u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsWithLearnedPositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, n_vocab: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Embedding(n_vocab, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.positional_encodings = nn.Parameter(torch.zeros(max_len, 1, d_model), requires_grad=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        pe = self.positional_encodings[:x.shape[0]]\n",
        "        return self.linear(x) * math.sqrt(self.d_model) + pe"
      ],
      "metadata": {
        "id": "VAyKmdAiwm_I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SHipSNIyvqgi"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, *,\n",
        "                 d_model: int,\n",
        "                 self_attn: MultiHeadAttention,\n",
        "                 src_attn: MultiHeadAttention = None,\n",
        "                 feed_forward: FeedForward,\n",
        "                 dropout_prob: float):\n",
        "          super().__init__()\n",
        "          self.size = d_model\n",
        "          self.self_attn = self_attn\n",
        "          self.src_attn = src_attn\n",
        "          self.feed_forward = feed_forward\n",
        "          self.dropout = nn.Dropout(dropout_prob)\n",
        "          self.norm_self_attn = nn.LayerNorm([d_model])\n",
        "          if self.src_attn is not None:\n",
        "              self.norm_src_attn = nn.LayerNorm([d_model])\n",
        "          self.norm_ff = nn.LayerNorm([d_model])\n",
        "\n",
        "#Whether to save input to the feed forward layer\n",
        "\n",
        "          self.is_save_ff_input = False\n",
        "\n",
        "    def forward(self, *,\n",
        "                x: torch.Tensor,\n",
        "                mask: torch.Tensor,\n",
        "                src: torch.Tensor = None,\n",
        "                src_mask: torch.Tensor = None):\n",
        "\n",
        "#Normalize the vectors before doing self attention\n",
        "        z = self.norm_self_attn(x)\n",
        "#Run through self attention, i.e. keys and values are from self\n",
        "        self_attn = self.self_attn(query=z, key=z, value=z, mask=mask)\n",
        "#Add the self attention results\n",
        "        x = x + self.dropout(self_attn)\n",
        "#If a source is provided, get results from attention to source. This is when you have a decoder layer that pays attention to encoder outputs\n",
        "        if src is not None:\n",
        "#Normalize vectors\n",
        "           z = self.norm_src_attn(x)\n",
        "#Attention to source. i.e. keys and values are from source\n",
        "           attn_src = self.src_attn(query=z, key=src, value=src, mask=src_mask)\n",
        "#Add the source attention results\n",
        "           x = x + self.dropout(attn_src)\n",
        "#Normalize for feed-forward\n",
        "        z = self.norm_ff(x)\n",
        "\n",
        "#Save the input to the feed forward layer if specified\n",
        "\n",
        "        if self.is_save_ff_input:\n",
        "            self.ff_input = z.clone()\n",
        "\n",
        "#Pass through the feed-forward network\n",
        "\n",
        "        ff = self.feed_forward(z)\n",
        "\n",
        "#Add the feed-forward results back\n",
        "        x = x + self.dropout(ff)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layer: TransformerLayer, n_layers: int):\n",
        "        super().__init__()\n",
        "\n",
        "#Make copies of the transformer layer\n",
        "        self.layers = clone_module_list(layer, n_layers)\n",
        "\n",
        "#Final normalization layer\n",
        "        self.norm = nn.LayerNorm([layer.size])\n",
        "\n",
        "    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n",
        "#Run through each transformer layer\n",
        "\n",
        "       for layer in self.layers:\n",
        "            x = layer(x=x, mask=mask)\n",
        "#Finally, normalize the vectors\n",
        "       return self.norm(x)"
      ],
      "metadata": {
        "id": "g_T0OZa_672B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layer: TransformerLayer, n_layers: int):\n",
        "        super().__init__()\n",
        "        self.layers = clone_module_list(layer, n_layers)\n",
        "        self.norm = nn.LayerNorm([layer.size])\n",
        "\n",
        "    def forward(self, x: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor):\n",
        "        for layer in self.layers:\n",
        "           x = layer(x=x, mask=tgt_mask, src=memory, src_mask=src_mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "fxNSrmnI-fiZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "   def __init__(self, n_vocab: int, d_model: int):\n",
        "       super().__init__()\n",
        "       self.projection = nn.Linear(d_model, n_vocab)\n",
        "\n",
        "   def forward(self, x):\n",
        "        return self.projection(x)"
      ],
      "metadata": {
        "id": "6iVSjP9nBVQb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: nn.Module, tgt_embed: nn.Module, generator: nn.Module):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor):\n",
        "        enc = self.encode(src, src_mask)\n",
        "        return self.decode(enc, src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src: torch.Tensor, src_mask: torch.Tensor):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory: torch.Tensor, src_mask: torch.Tensor, tgt: torch.Tensor, tgt_mask: torch.Tensor):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ],
      "metadata": {
        "id": "v5U21QVZC9i8"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}